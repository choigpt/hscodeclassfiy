# Heading Terms Integration Report

**Date**: 2026-02-03
**Author**: Claude Code
**Objective**: heading_terms ë¡œë“œ â†’ dataset ì¬ë¹Œë“œ â†’ ranker ì¬í•™ìŠµ â†’ í‰ê°€ â†’ í”¼ì²˜ í™œì„±í™” í™•ì¸

---

## Executive Summary

### âœ… ë‹¬ì„±ëœ ëª©í‘œ

1. **heading_terms ë¡œë“œ ì™„ë£Œ**: 1,239ê°œ HS4 ì½”ë“œì˜ í˜¸ ìš©ì–´ (title_ko + scope)
2. **í”¼ì²˜ ê³„ì‚° êµ¬í˜„**: LegalGateì— heading_term_score ë§¤ì¹­ ë¡œì§ ì¶”ê°€
3. **Dataset ì¬ë¹Œë“œ**: ì „ì²´ 7,198ìƒ˜í”Œ â†’ 168,677 í›„ë³´ ìŒ
4. **Ranker ì¬í•™ìŠµ**: f_legal_heading_term importance = 280.99 (rank #24)
5. **ëª¨ë“œ ë¶„ë¦¬ ê²€ì¦**: KB-only retriever_used=0.0, Hybrid=1.0

### âš ï¸ ë°œê²¬ëœ ë¬¸ì œ

1. **Hybrid ì„±ëŠ¥ ì €í•˜**: KB-only (12%) > Hybrid (7.5%) - 37.5% í•˜ë½
2. **í”¼ì²˜ ì˜í–¥ë ¥ ì œí•œì **: f_legal_heading_termì´ í™œì„±í™”ë˜ì—ˆìœ¼ë‚˜ ì˜ˆì¸¡ ë³€ê²½ ì—†ìŒ
3. **f_lexical ì••ë„ì  ìš°ì„¸**: 251,890 vs 281 (900ë°° ì°¨ì´)

---

## Step 1: Heading Terms ë¡œë“œ êµ¬í˜„

### 1.1 êµ¬í˜„ ë‚´ìš©

**íŒŒì¼**: `src/classifier/legal_gate.py`

```python
def _load_heading_terms(self) -> Dict[str, List[str]]:
    """HS4 í˜¸ ìš©ì–´ ë¡œë“œ (title_ko + scope í† í°)"""
    heading_terms = {}
    cards_path = Path("kb/structured/hs4_cards.jsonl")

    with open(cards_path, 'r', encoding='utf-8') as f:
        for line in f:
            card = json.loads(line)
            hs4 = card.get('hs4')
            terms = []

            # Title (heading)
            title = card.get('title_ko', '')
            if title:
                title_norm = normalize(title)
                title_tokens = [t for t in title_norm.split() if len(t) >= 2]
                terms.extend(title_tokens)

            # Scope (keywords)
            scope = card.get('scope', [])
            for keyword in scope:
                kw_norm = normalize(keyword)
                kw_tokens = [t for t in kw_norm.split() if len(t) >= 2]
                terms.extend(kw_tokens)

            if terms:
                heading_terms[hs4] = list(set(terms))

    return heading_terms
```

### 1.2 Heading Term ë§¤ì¹­ ë¡œì§

**íŒŒì¼**: `src/classifier/legal_gate.py:262-290`

```python
# 1. Heading term match (í˜¸ ìš©ì–´ ë§¤ì¹­)
if hs4 in self.heading_terms:
    terms = self.heading_terms[hs4]
    matched_terms = []

    for term in terms:
        if simple_contains(input_norm, term):
            # ì§ì ‘ ë§¤ì¹­: 0.1ì 
            result.heading_term_score += 0.1
            matched_terms.append(term)
        else:
            # Fuzzy ë§¤ì¹­: 0.05ì 
            match_result, _ = fuzzy_match(input_norm, term)
            if match_result:
                result.heading_term_score += 0.05
                matched_terms.append(f"~{term}")

    # ì ìˆ˜ í´ë¦¬í•‘ (ìµœëŒ€ 1.0)
    result.heading_term_score = min(result.heading_term_score, 1.0)

    # ì¦ê±° ì¶”ê°€
    if matched_terms:
        result.evidence.append(Evidence(
            kind='legal_heading_term',
            source_id=hs4,
            text=f"í˜¸ ìš©ì–´ ë§¤ì¹­: {', '.join(matched_terms[:5])}",
            weight=result.heading_term_score
        ))
```

### 1.3 ë¡œë“œ ê²°ê³¼

```
[LegalGate] Heading terms loaded: 1239 HS4
```

**í†µê³„**:
- ì´ HS4 ì½”ë“œ: 1,239ê°œ
- í‰ê·  term ìˆ˜/HS4: ~15ê°œ (ì¶”ì •)
- ì •ê·œí™”: normalize() í•¨ìˆ˜ ì ìš© (ì†Œë¬¸ì, ê³µë°± ì •ë¦¬)
- ìµœì†Œ í† í° ê¸¸ì´: 2ì

---

## Step 2: Dataset ì¬ë¹Œë“œ

### 2.1 ì†ŒëŸ‰ ê²€ì¦ (200ìƒ˜í”Œ)

**ëª…ë ¹**: `python -m src.classifier.rank.build_dataset_legal 200`

**ê²°ê³¼**:
- ì²˜ë¦¬ ìƒ˜í”Œ: 200
- ì´ í›„ë³´ ìŒ: 4,831
- f_legal_heading_term nonzero_rate: **7.33%** âœ“

### 2.2 ì „ì²´ Dataset ì¬ë¹Œë“œ

**ëª…ë ¹**: `python -m src.classifier.rank.train_ranker_legal --build`

**ê²°ê³¼**:
```
ì „ì²´ ìƒ˜í”Œ: 7198
ì²˜ë¦¬ ì™„ë£Œ: 7196
ì´ í›„ë³´ ìŒ: 168,677
ì •ë‹µ í›„ë³´ ìŒ: 7,196 (4.27%)

í‰ê·  í›„ë³´ ìˆ˜ (LegalGate ì „): 23.3
í‰ê·  í›„ë³´ ìˆ˜ (LegalGate í›„): 23.4
LegalGate í•„í„°ë§ íš¨ê³¼: -0.5%
```

### 2.3 Feature ë¶„í¬

| Feature | Nonzero Rate | Mean | Range |
|---------|--------------|------|-------|
| f_legal_scope_match_score | 0.43% | 0.0015 | [0, 0.5] |
| **f_legal_heading_term** | **8.27%** | **0.0087** | **[0, 0.5]** |
| f_legal_include_support | 1.17% | 0.0003 | [0, 0.18] |
| f_legal_exclude_conflict | 3.78% | -0.0016 | [-0.36, 0] |
| f_legal_redirect_penalty | 0.94% | -0.0004 | [-0.3, 0] |

**ë¶„ì„**:
- heading_termì´ 168,677ê°œ í›„ë³´ ì¤‘ **13,946ê°œ (8.27%)** ì—ì„œ í™œì„±í™”
- í‰ê·  ì ìˆ˜ëŠ” ë‚®ìŒ (0.0087) â†’ ëŒ€ë¶€ë¶„ 0.1~0.2 ë²”ìœ„

---

## Step 3: Ranker ì¬í•™ìŠµ

### 3.1 í•™ìŠµ êµ¬ì„±

**Train/Test Split**:
- Train: 5,757 queries (134,968 samples)
- Test: 1,439 queries (33,709 samples)

**Early Stopping**:
- Best iteration: 189
- Validation rounds: 50

### 3.2 ì„±ëŠ¥ ì§€í‘œ

| Metric | Train | Test |
|--------|-------|------|
| NDCG@1 | 0.8064 | 0.7802 |
| NDCG@3 | 0.8649 | 0.8458 |
| NDCG@5 | 0.8856 | 0.8716 |

**ë¶„ì„**:
- Test NDCG@1=0.78ì€ ì–‘í˜¸í•œ ìˆ˜ì¤€
- Train/Test ì°¨ì´ê°€ ì‘ì•„ overfitting ì—†ìŒ

### 3.3 Feature Importance (Top 20)

| Rank | Feature | Importance |
|------|---------|------------|
| 1 | f_lexical | 251,890.46 |
| 2 | f_specificity | 5,435.30 |
| 3 | f_form_match_score | 5,122.08 |
| 4 | f_material_match_score | 4,974.64 |
| 5 | f_card_hits | 3,306.57 |
| 6 | f_uncertainty_penalty | 2,895.61 |
| ... | ... | ... |
| 16 | **f_legal_exclude_conflict** | **947.22** |
| 18 | **f_legal_include_support** | **470.25** |
| 21 | **f_legal_redirect_penalty** | **341.56** |
| **24** | **f_legal_heading_term** | **280.99** âœ“ |
| 26 | **f_legal_scope_match_score** | **144.20** |

### 3.4 LegalGate Features ìš”ì•½

**ëª¨ë“  5ê°œ í”¼ì²˜ê°€ í™œì„±í™”ë¨**:
1. f_legal_exclude_conflict: 947.22 (rank #16)
2. f_legal_include_support: 470.25 (rank #18)
3. f_legal_redirect_penalty: 341.56 (rank #21)
4. **f_legal_heading_term: 280.99 (rank #24)** âœ…
5. f_legal_scope_match_score: 144.20 (rank #26)

**ë¹„êµ (200ìƒ˜í”Œ ëª¨ë¸ vs ì „ì²´ ë°ì´í„° ëª¨ë¸)**:

| Feature | 200ìƒ˜í”Œ | ì „ì²´ ë°ì´í„° |
|---------|---------|-------------|
| f_legal_heading_term | 0.00 (ë¯¸ì‚¬ìš©) | 280.99 (ì‚¬ìš©) âœ“ |
| f_legal_exclude_conflict | 19.35 | 947.22 |

---

## Step 4: 200ìƒ˜í”Œ ì¬í‰ê°€ (KB-only vs Hybrid)

### 4.1 í‰ê°€ ì„¤ì •

- **Dataset**: all_cases_full_v7.json
- **Samples**: 200 (test split, seed=42)
- **Modes**: kb_only, hybrid

### 4.2 ì„±ëŠ¥ ë¹„êµ

| Metric | KB-only | Hybrid | ì°¨ì´ |
|--------|---------|--------|------|
| **top1_accuracy** | **0.1200** | **0.0750** | **-37.5%** âš ï¸ |
| top3_accuracy | 0.2350 | 0.1400 | -40.4% |
| top5_accuracy | 0.3550 | 0.1900 | -46.5% |
| ECE | 0.7814 | 0.8293 | +6.1% (worse) |
| Brier Score | 0.7388 | 0.7643 | +3.5% (worse) |

**ê²°ë¡ **: **Hybrid ëª¨ë“œê°€ KB-onlyë³´ë‹¤ ëª¨ë“  ì§€í‘œì—ì„œ ì €ì¡°**

### 4.3 Usage ë¹„êµ

| Component | KB-only | Hybrid |
|-----------|---------|--------|
| retriever_usage_rate | 0.0 âœ“ | 1.0 âœ“ |
| ranker_usage_rate | 0.0 âœ“ | 1.0 âœ“ |
| avg_cards_hits | 3.61 | 3.68 |
| avg_rule_hits | 0.03 | 0.07 |

**ëª¨ë“œ ë¶„ë¦¬ ì •ìƒ ì‘ë™**:
- KB-onlyëŠ” ML retriever/rankerë¥¼ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
- HybridëŠ” ëª¨ë“  ìƒ˜í”Œì—ì„œ ML retriever/ranker ì ìš©

### 4.4 ì˜ˆì¸¡ ì°¨ì´

**top1_same_rate**: 0.82 (< 0.95 ê¸°ì¤€ ì¶©ì¡±) âœ“

- ë™ì¼í•œ top-1: 164/200 (82%)
- ë‹¤ë¥¸ top-1: 36/200 (18%)

**ê²°ë¡ **: ë‘ ëª¨ë“œê°€ ì¶©ë¶„íˆ ë‹¤ë¥¸ ì˜ˆì¸¡ì„ ìƒì„±í•¨

### 4.5 ëª¨ë¸ ê°„ ë¹„êµ (200ìƒ˜í”Œ vs ì „ì²´ ë°ì´í„°)

**KB-only**:
- top1_accuracy: 0.12 â†’ 0.12 (ë³€í™” ì—†ìŒ)
- ë™ì¼í•œ ì˜ˆì¸¡: 200/200 (100%)

**Hybrid**:
- top1_accuracy: 0.075 â†’ 0.075 (ë³€í™” ì—†ìŒ)
- ë™ì¼í•œ ì˜ˆì¸¡: 200/200 (100%)

**ê²°ë¡ **: f_legal_heading_termì´ í™œì„±í™”ë˜ì—ˆìœ¼ë‚˜, ì´ 200ìƒ˜í”Œì—ì„œëŠ” ì˜ˆì¸¡ì„ ë³€ê²½í•˜ì§€ ì•ŠìŒ. f_lexicalì´ ë„ˆë¬´ dominantí•¨ (251,890 vs 281).

---

## Step 5: Calibration ì§„ë‹¨

### 5.1 Confidence ë¶„ì„

**ë¬¸ì œ**: ëª¨ë“  ì˜ˆì¸¡ì˜ confidence=0.0

```python
KB-only:
  Accuracy: 12.00%
  Avg Confidence: 0.00%
  Calibration Gap: 12.00%
  Confidence range: [0.0000, 0.0000]

Hybrid:
  Accuracy: 7.50%
  Avg Confidence: 0.00%
  Calibration Gap: 7.50%
  Confidence range: [0.0000, 0.0000]
```

**ì›ì¸**:
1. Classification-level confidenceê°€ ê³„ì‚°ë˜ì§€ ì•ŠìŒ
2. GRI signal confidenceë§Œ ì¡´ì¬ (gri1_note_like, gri2a_incomplete ë“±)
3. score_totalì€ ìˆìœ¼ë‚˜ í™•ë¥ ë¡œ ë³€í™˜ë˜ì§€ ì•ŠìŒ

### 5.2 ECE ë¶„ì„

**KB-only**: ECE=0.7814 (ë§¤ìš° ë†’ìŒ)
**Hybrid**: ECE=0.8293 (ë” ë†’ìŒ)

**ë¬¸ì œ**:
- Ranker scoreëŠ” í™•ë¥ ì´ ì•„ë‹˜ (3.86 ê°™ì€ ê°’)
- Calibration layer (temperature scaling, isotonic regression) ì—†ìŒ
- AUTO thresholdê°€ score ê¸°ë°˜ì´ ì•„ë‹Œ ì„ì˜ ì„¤ì •

### 5.3 ê¶Œì¥ ìˆ˜ì •

1. **Calibration Layer ì¶”ê°€**:
   ```python
   from sklearn.calibration import CalibratedClassifierCV

   # Ranker ì ìˆ˜ë¥¼ í™•ë¥ ë¡œ ë³€í™˜
   calibrated_probs = calibrator.predict_proba(ranker_scores)
   confidence = calibrated_probs[top1_idx]
   ```

2. **AUTO Threshold ì¬ì„¤ì •**:
   - í˜„ì¬: ì„ì˜ threshold
   - ê¶Œì¥: calibrated probability > 0.7 + legal_conflict=0 + fact_sufficient=True

3. **GRI Confidence í†µí•©**:
   - GRI signal confidenceë¥¼ classification confidenceì— ë°˜ì˜
   - ë¶ˆí™•ì‹¤ì„±ì´ ë†’ìœ¼ë©´ confidence ê°ì†Œ

---

## í•µì‹¬ ë¬¸ì œ ë° ì›ì¸ ë¶„ì„

### ë¬¸ì œ 1: Hybrid ì„±ëŠ¥ ì €í•˜ (KB-only 12% > Hybrid 7.5%)

**ê°€ì„¤ 1: ML Retriever í’ˆì§ˆ ë¬¸ì œ**

```
KB-only:
  candidate_recall_5: 0.355 (35.5%)

Hybrid:
  candidate_recall_5: 0.190 (19.0%)
```

**ë¶„ì„**:
- ML retrieverê°€ top-50 í›„ë³´ ì¤‘ ì •ë‹µì„ í¬í•¨í•˜ëŠ” ë¹„ìœ¨ì´ ë‚®ìŒ
- KB retrieval (lexical + cards)ì´ ë” íš¨ê³¼ì 
- Hybridì—ì„œ ML í›„ë³´ê°€ KB í›„ë³´ë¥¼ ë°€ì–´ë‚´ë©´ì„œ recall í•˜ë½

**ê°€ì„¤ 2: Ranker íš¨ê³¼ ë¶€ì¡±**

```
Ranker NDCG@1 (í•™ìŠµ): 0.78
ì‹¤ì œ top1_accuracy: 0.075
```

**ë¶„ì„**:
- RankerëŠ” í•™ìŠµ ë°ì´í„°ì—ì„œ 78% NDCG ë‹¬ì„±
- í•˜ì§€ë§Œ ì‹¤ì „ì—ì„œëŠ” 7.5% accuracy (10ë°° ì°¨ì´)
- Train/Test splitì˜ distribution shift ê°€ëŠ¥ì„±

**ê°€ì„¤ 3: Feature Dominance (f_lexical)**

```
f_lexical: 251,890.46 (90% ì´ìƒ ê¸°ì—¬)
f_legal_heading_term: 280.99 (0.1% ê¸°ì—¬)
```

**ë¶„ì„**:
- f_lexicalì´ ì••ë„ì ìœ¼ë¡œ ê°•í•¨
- ë‹¤ë¥¸ í”¼ì²˜ë“¤ì€ ë¯¸ì„¸ ì¡°ì • ìˆ˜ì¤€
- heading_termì´ í™œì„±í™”ë˜ì–´ë„ ì˜ˆì¸¡ì— í° ì˜í–¥ ì—†ìŒ

### ë¬¸ì œ 2: f_legal_heading_term ì˜í–¥ë ¥ ì œí•œ

**Dataset ìˆ˜ì¤€**:
- nonzero_rate: 8.27% (ì¶©ë¶„í•¨)
- mean: 0.0087 (ë„ˆë¬´ ë‚®ìŒ)
- range: [0, 0.5]

**ëª¨ë¸ ìˆ˜ì¤€**:
- importance: 280.99 (rank #24)
- f_lexical ëŒ€ë¹„ ë¹„ìœ¨: 1:896

**ì˜ˆì¸¡ ìˆ˜ì¤€**:
- 200ìƒ˜í”Œ ì¤‘ ì˜ˆì¸¡ ë³€ê²½: 0ê°œ (0%)
- ë™ì¼ ì˜ˆì¸¡: 200ê°œ (100%)

**ì›ì¸**:
1. **ìŠ¤ì¼€ì¼ ë¶ˆê· í˜•**: heading_term_score ìµœëŒ€ 0.5 vs f_lexical ìµœëŒ€ ìˆ˜ì‹­
2. **í¬ì†Œì„±**: 8.27%ë§Œ í™œì„±í™” â†’ ëŒ€ë¶€ë¶„ 0
3. **ì‹ í˜¸ ì•½í•¨**: ë§¤ì¹­ë˜ì–´ë„ 0.1~0.2 ì ìˆ˜ (ë¯¸ë¯¸í•¨)

### ë¬¸ì œ 3: Calibration ë¯¸êµ¬í˜„

**í˜„ìƒ**:
- ëª¨ë“  confidence=0.0
- ECE=0.78~0.83 (uncalibrated)
- AUTO/ASK íŒë‹¨ ê¸°ì¤€ ì—†ìŒ

**ì˜í–¥**:
- ì‚¬ìš©ìì—ê²Œ ì‹ ë¢°ë„ í‘œì‹œ ë¶ˆê°€
- ASK ë¼ìš°íŒ…ì´ ì„ì˜ì 
- Production ë°°í¬ ë¶ˆê°€ëŠ¥

---

## ê¶Œì¥ ì¡°ì¹˜ (ìš°ì„ ìˆœìœ„ìˆœ)

### 1. ML Retriever ê°œì„  ë˜ëŠ” ë¹„í™œì„±í™” (High Priority)

**ì˜µì…˜ A: ML Retriever ì œê±°**
```python
# KB-only ëª¨ë“œë¥¼ ê¸°ë³¸ìœ¼ë¡œ ì‚¬ìš©
pipeline = HSPipeline(retriever=None, ranker=None)
```

**ì¥ì **:
- ì¦‰ì‹œ ì„±ëŠ¥ 12% í™•ë³´
- ì•ˆì •ì ì´ê³  í•´ì„ ê°€ëŠ¥

**ë‹¨ì **:
- MLì˜ ì´ì  í¬ê¸°
- í™•ì¥ì„± ì œí•œ

**ì˜µì…˜ B: ML Retriever ì¬í•™ìŠµ**
- ë” ë‚˜ì€ embedding ëª¨ë¸ (jhgan/ko-sroberta â†’ ìµœì‹  ëª¨ë¸)
- Negative sampling ê°œì„ 
- Hard negative mining

### 2. Feature ìŠ¤ì¼€ì¼ ì¡°ì • (Medium Priority)

**heading_term_score ê°€ì¤‘ì¹˜ ì¦ê°€**:
```python
# í˜„ì¬: ì§ì ‘ ë§¤ì¹­ 0.1, fuzzy 0.05, ìµœëŒ€ 1.0
# ì œì•ˆ: ì§ì ‘ ë§¤ì¹­ 0.5, fuzzy 0.25, ìµœëŒ€ 5.0
result.heading_term_score += 0.5  # 5ë°° ì¦ê°€
result.heading_term_score = min(result.heading_term_score, 5.0)
```

**f_lexical ì •ê·œí™”**:
```python
# í˜„ì¬: card ë§¤ì¹­ë‹¹ 0.5~1.5 ë¬´ì œí•œ ëˆ„ì 
# ì œì•ˆ: card ì ìˆ˜ë¥¼ log scaleë¡œ ë³€í™˜
f_lexical = np.log1p(card_score_sum)
```

### 3. Calibration Layer êµ¬í˜„ (High Priority for Production)

**Temperature Scaling**:
```python
from sklearn.calibration import CalibratedClassifierCV

# Ranker ì¶œë ¥ì„ í™•ë¥ ë¡œ ë³€í™˜
calibrator = CalibratedClassifierCV(ranker, method='sigmoid')
calibrator.fit(val_scores, val_labels)

confidence = calibrator.predict_proba(test_score)[0, 1]
```

**AUTO Threshold**:
```python
# ê¸°ì¡´: score_total > threshold (ì„ì˜)
# ì œì•ˆ: confidence > 0.7 AND legal_conflict=False AND fact_sufficient=True
auto_eligible = (
    confidence > 0.7 and
    result.legal_conflict == False and
    result.fact_sufficient == True
)
```

### 4. ì „ì²´ ë°ì´í„° ì¬í‰ê°€ (Medium Priority)

**í˜„ì¬**: 200ìƒ˜í”Œë§Œ í‰ê°€
**ê¶Œì¥**: ì „ì²´ test split (1,440ìƒ˜í”Œ) í‰ê°€

```bash
# ì „ì²´ test split í‰ê°€
python -m src.classifier.eval.run_eval --mode kb_only --split test --seed 42
python -m src.classifier.eval.run_eval --mode hybrid --split test --seed 42
```

**ëª©ì **:
- 200ìƒ˜í”Œì€ ëŒ€í‘œì„± ë¶€ì¡± ê°€ëŠ¥ì„±
- ë” í° ìƒ˜í”Œì—ì„œ heading_term íš¨ê³¼ í™•ì¸
- Statistical significance ê²€ì¦

---

## ê²°ë¡ 

### âœ… ì„±ê³µí•œ ë¶€ë¶„

1. **heading_terms ë¡œë“œ**: 1,239ê°œ HS4, 8.27% í™œì„±í™”ìœ¨
2. **í”¼ì²˜ êµ¬í˜„**: LegalGate heading_term_score ê³„ì‚° ë¡œì§ ì¶”ê°€
3. **ëª¨ë¸ í•™ìŠµ**: f_legal_heading_term importance=280.99 ë‹¬ì„±
4. **ëª¨ë“œ ë¶„ë¦¬**: KB-only vs Hybrid ì •ìƒ ì‘ë™

### âš ï¸ ê°œì„  í•„ìš”í•œ ë¶€ë¶„

1. **Hybrid ì„±ëŠ¥**: KB-only (12%) > Hybrid (7.5%)
2. **í”¼ì²˜ ì˜í–¥ë ¥**: heading_term í™œì„±í™”ë˜ì—ˆìœ¼ë‚˜ ì˜ˆì¸¡ ë¶ˆë³€
3. **Calibration**: confidence=0, ECE=0.78~0.83

### ğŸ¯ ë‹¤ìŒ ë‹¨ê³„

**ì¦‰ì‹œ ì¡°ì¹˜**:
1. ML Retriever ì œê±° ë˜ëŠ” ê°œì„ 
2. Calibration layer êµ¬í˜„
3. Feature scaling ì¡°ì •

**ì¤‘ê¸° ì¡°ì¹˜**:
1. ì „ì²´ test split (1,440ìƒ˜í”Œ) ì¬í‰ê°€
2. heading_term ê°€ì¤‘ì¹˜ ì¦ê°€ ì‹¤í—˜
3. f_lexical ì •ê·œí™”

**ì¥ê¸° ì¡°ì¹˜**:
1. ML Retriever ì¬í•™ìŠµ (ë” ë‚˜ì€ ëª¨ë¸)
2. Ensemble approach (KB + ML voting)
3. Active learningìœ¼ë¡œ ì–´ë ¤ìš´ ì¼€ì´ìŠ¤ í•™ìŠµ

---

## ì‚°ì¶œë¬¼

### ì½”ë“œ ë³€ê²½

1. `src/classifier/legal_gate.py`:
   - `_load_heading_terms()` ë©”ì„œë“œ ì¶”ê°€
   - `_evaluate_candidate()` heading term ë§¤ì¹­ ë¡œì§ êµ¬í˜„

2. `artifacts/ranker_legal/`:
   - `rank_features_legal.csv` (168,677 rows, f_legal_heading_term í™œì„±)
   - `model_legal.txt` (LightGBM ëª¨ë¸, importance=280.99)
   - `train_results_legal.json` (NDCG@1=0.78)

### í‰ê°€ ê²°ê³¼

1. `artifacts/eval/kb_only_20260203_192931/`:
   - metrics_summary.json (top1=0.12)
   - usage_summary.json (retriever_used=0.0)

2. `artifacts/eval/hybrid_20260203_193049/`:
   - metrics_summary.json (top1=0.075)
   - usage_summary.json (retriever_used=1.0)

### ë¬¸ì„œ

1. `docs/HEADING_TERMS_INTEGRATION_REPORT.md` (ë³¸ ë¬¸ì„œ)
2. `docs/CALIBRATION_DIAG.md` (ë‹¤ìŒ ë‹¨ê³„ì—ì„œ ì‘ì„± ì˜ˆì •)
3. `docs/COMPARE_KB_ONLY_VS_HYBRID.md` (ì—…ë°ì´íŠ¸ ì˜ˆì •)

---

**Report Generated**: 2026-02-03 19:35 KST
**Status**: Complete (with recommendations for improvement)
